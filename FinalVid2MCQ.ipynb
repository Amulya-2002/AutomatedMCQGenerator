{"cells":[{"cell_type":"markdown","metadata":{"id":"lpcTL4f2G9WE"},"source":["## Installation of libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18106,"status":"ok","timestamp":1683300777453,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"zwn75S4Ca11c","outputId":"1f2ca74c-b9d7-4b26-9aaf-334b5320fb68"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/boudinfl/pke.git\n","  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-tyb6aba7\n","  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-tyb6aba7\n","  Resolved https://github.com/boudinfl/pke.git to commit ebd6e5754b4156a61a4ec6c4c283e821d11a36be\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.8.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (2.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.8.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.2.2)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.3.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (0.18.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.2.0)\n","Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.5.2)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.4)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.1.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (6.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.65.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.27.1)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (23.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from networkx->pke==2.0.0) (3.7.1)\n","Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from networkx->pke==2.0.0) (1.5.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (2022.10.31)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pke==2.0.0) (3.1.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (4.39.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (8.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx->pke==2.0.0) (2022.7.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.4)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.7.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->networkx->pke==2.0.0) (1.16.0)\n"]}],"source":["!pip install --quiet flashtext==2.7\n","!pip install git+https://github.com/boudinfl/pke.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43896,"status":"ok","timestamp":1683300821347,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"PM2h7czt2s0f","outputId":"bdcd833c-85e0-4ae1-d047-b6e783919f74"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install --quiet transformers==4.8.1\n","!pip install --quiet sentencepiece==0.1.95\n","!pip install --quiet textwrap3==0.9.2\n","!pip install --quiet gradio==3.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbiUd-SkcDFn"},"outputs":[],"source":["!pip install --quiet strsim==0.0.3\n","!pip install --quiet sense2vec==2.0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4823,"status":"ok","timestamp":1683300834415,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"cDHhiuKJ2eva","outputId":"34311a2a-799b-451a-9dcc-c88c32142aad"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 359 µs (started: 2023-05-05 15:33:54 +00:00)\n"]}],"source":["!pip install --quiet ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8237,"status":"ok","timestamp":1683300842649,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"tJwVkHS-eSnv","outputId":"50ddbbc9-668d-4d12-a576-f4f5f99ff549"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 4.92 s (started: 2023-05-05 15:33:54 +00:00)\n"]}],"source":["!pip install --quiet sentence-transformers==2.2.2"]},{"cell_type":"markdown","metadata":{"id":"_a4aKqRxe3-i"},"source":["The below code restarts the colab notebook. Once it is restarted continue from next section and no need to run this section (installation) again."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5824,"status":"ok","timestamp":1683300848460,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"aA7g4bf84HVb","outputId":"712d8ce0-38e7-4e51-b06d-3b37c29b735e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scipy==1.8.0 in /usr/local/lib/python3.10/dist-packages (1.8.0)\n","Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scipy==1.8.0) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: networkx==2.6 in /usr/local/lib/python3.10/dist-packages (2.6)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (3.7.1)\n","Requirement already satisfied: scipy!=1.6.1,>=1.5 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (1.8.0)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (1.22.4)\n","Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from networkx==2.6) (1.5.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (23.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (8.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx==2.6) (4.39.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx==2.6) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->networkx==2.6) (1.16.0)\n","time: 8.44 s (started: 2023-05-05 15:33:59 +00:00)\n"]}],"source":["!pip install scipy==1.8.0\n","!pip install networkx==2.6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9191,"status":"ok","timestamp":1683300857649,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"A22iAY2tRKV5","outputId":"762ec1f2-13c3-4890-f8ec-1e902d0f776f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n","time: 10 s (started: 2023-05-05 15:34:07 +00:00)\n"]}],"source":["!pip install SpeechRecognition\n","!pip install moviepy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683300857650,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"sp7gjW5HfRjL","outputId":"25d9e0d8-d96f-49ac-d119-13d2598a1e18"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 337 µs (started: 2023-05-05 15:34:17 +00:00)\n"]}],"source":["# restart runtime\n","quit()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qwSTl62XeYS"},"outputs":[],"source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QhvoMvG6bHNL"},"outputs":[],"source":["from textwrap3 import wrap"]},{"cell_type":"markdown","metadata":{"id":"imbR470g15Fq"},"source":["# **Summarization with T5**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19040,"status":"ok","timestamp":1683300892233,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"9cXs7fnvCarm","outputId":"061609bc-9b1b-4c68-f1df-545001b9d0d3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}],"source":["import torch\n","from transformers import T5ForConditionalGeneration,T5Tokenizer\n","summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","summary_model = summary_model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzGsTUJ8TyAN"},"outputs":[],"source":["import random\n","import numpy as np\n","\n","def set_seed(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3547,"status":"ok","timestamp":1683300895770,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"8JaEy5Xw_UMf","outputId":"f39ca411-a004-4c2e-beda-439a1a8d1d03"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('brown')\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet as wn\n","from nltk.tokenize import sent_tokenize\n","\n","def postprocesstext (content):\n","  final=\"\"\n","  for sent in sent_tokenize(content):\n","    sent = sent.capitalize()\n","    final = final +\" \"+sent\n","  return final\n","\n","\n","def summarizer(text,model,tokenizer):\n","  text = text.strip().replace(\"\\n\",\" \")\n","  text = \"summarize: \"+text\n","  # print (text)\n","  max_len = 512\n","  encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n","\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","\n","  outs = model.generate(input_ids=input_ids,\n","                                  attention_mask=attention_mask,\n","                                  early_stopping=True,\n","                                  num_beams=3,\n","                                  num_return_sequences=1,\n","                                  no_repeat_ngram_size=2,\n","                                  min_length = 75,\n","                                  max_length=300)\n","\n","\n","  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n","  summary = dec[0]\n","  summary = postprocesstext(summary)\n","  summary= summary.strip()\n","\n","  return summary\n"]},{"cell_type":"markdown","metadata":{"id":"N0YrWTxQCo9q"},"source":["# **Answer Span Extraction (Keywords and Noun Phrases)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20076,"status":"ok","timestamp":1683300915836,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"84DxJGFn4MfD","outputId":"884d33d3-b4bf-4180-b3f8-35a1f8bdb355"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import string\n","import pke\n","import traceback\n","\n","def get_nouns_multipartite(content):\n","    out=[]\n","    try:\n","        extractor = pke.unsupervised.MultipartiteRank()\n","        extractor.load_document(input=content,language='en')\n","        #    not contain punctuation marks or stopwords as candidates.\n","        pos = {'PROPN','NOUN'}\n","        #pos = {'PROPN','NOUN'}\n","        stoplist = list(string.punctuation)\n","        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n","        stoplist += stopwords.words('english')\n","        # extractor.candidate_selection(pos=pos, stoplist=stoplist)\n","        extractor.candidate_selection(pos=pos)\n","        # 4. build the Multipartite graph and rank candidates using random walk,\n","        #    alpha controls the weight adjustment mechanism, see TopicRank for\n","        #    threshold/method parameters.\n","        extractor.candidate_weighting(alpha=1.1,\n","                                      threshold=0.75,\n","                                      method='average')\n","        keyphrases = extractor.get_n_best(n=15)\n","\n","\n","        for val in keyphrases:\n","            out.append(val[0])\n","    except:\n","        out = []\n","        traceback.print_exc()\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_sRWHAd4Wwp"},"outputs":[],"source":["from flashtext import KeywordProcessor\n","\n","\n","def get_keywords(originaltext,summarytext):\n","  keywords = get_nouns_multipartite(originaltext)\n","  print (\"keywords unsummarized: \",keywords)\n","  keyword_processor = KeywordProcessor()\n","  for keyword in keywords:\n","    keyword_processor.add_keyword(keyword)\n","\n","  keywords_found = keyword_processor.extract_keywords(summarytext)\n","  keywords_found = list(set(keywords_found))\n","  print (\"keywords_found in summarized: \",keywords_found)\n","\n","  important_keywords =[]\n","  for keyword in keywords:\n","    if keyword in keywords_found:\n","      important_keywords.append(keyword)\n","\n","  return important_keywords[:4]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FXbq7b2WCaZ_"},"source":["# **Question generation with T5**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CuKlpL1Cj6C"},"outputs":[],"source":["question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n","question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n","question_model = question_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7uzA4uLJ_P48"},"outputs":[],"source":["def get_question(context,answer,model,tokenizer):\n","  text = \"context: {} answer: {}\".format(context,answer)\n","  encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","\n","  outs = model.generate(input_ids=input_ids,\n","                                  attention_mask=attention_mask,\n","                                  early_stopping=True,\n","                                  num_beams=5,\n","                                  num_return_sequences=1,\n","                                  no_repeat_ngram_size=2,\n","                                  max_length=72)\n","\n","\n","  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n","\n","\n","  Question = dec[0].replace(\"question:\",\"\")\n","  Question= Question.strip()\n","  return Question\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NcV4uNlmApdW"},"source":["# **Filter keywords with Maximum marginal Relevance**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17630,"status":"ok","timestamp":1683300966815,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"FWi5WM67BLhL","outputId":"648cce82-2a17-4163-ba29-eede409354d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-05-05 15:35:48--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230505T153549Z&X-Amz-Expires=300&X-Amz-Signature=4d1a1813a17f98ee38c9a19bd3167f1472f3657921078499d343d0f3627168fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n","--2023-05-05 15:35:49--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230505T153549Z&X-Amz-Expires=300&X-Amz-Signature=4d1a1813a17f98ee38c9a19bd3167f1472f3657921078499d343d0f3627168fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 600444501 (573M) [application/octet-stream]\n","Saving to: ‘s2v_reddit_2015_md.tar.gz.2’\n","\n","s2v_reddit_2015_md. 100%[===================>] 572.63M  13.7MB/s    in 7.6s    \n","\n","2023-05-05 15:35:57 (74.9 MB/s) - ‘s2v_reddit_2015_md.tar.gz.2’ saved [600444501/600444501]\n","\n","./._s2v_old\n","./s2v_old/\n","./s2v_old/._freqs.json\n","./s2v_old/freqs.json\n","./s2v_old/._vectors\n","./s2v_old/vectors\n","./s2v_old/._cfg\n","./s2v_old/cfg\n","./s2v_old/._strings.json\n","./s2v_old/strings.json\n","./s2v_old/._key2row\n","./s2v_old/key2row\n"]}],"source":["!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n","!tar -xvf  s2v_reddit_2015_md.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVBkX2IoBgd8"},"outputs":[],"source":["import numpy as np\n","from sense2vec import Sense2Vec\n","s2v = Sense2Vec().from_disk('s2v_old')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAqN2OZbQ51Z"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","# paraphrase-distilroberta-base-v1\n","sentence_transformer_model = SentenceTransformer('msmarco-distilbert-base-v3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kv-FoyLEdCGE"},"outputs":[],"source":["from similarity.normalized_levenshtein import NormalizedLevenshtein\n","normalized_levenshtein = NormalizedLevenshtein()\n","\n","def filter_same_sense_words(original,wordlist):\n","  filtered_words=[]\n","  base_sense =original.split('|')[1]\n","  print (base_sense)\n","  for eachword in wordlist:\n","    if eachword[0].split('|')[1] == base_sense:\n","      filtered_words.append(eachword[0].split('|')[0].replace(\"_\", \" \").title().strip())\n","  return filtered_words\n","\n","def get_highest_similarity_score(wordlist,wrd):\n","  score=[]\n","  for each in wordlist:\n","    score.append(normalized_levenshtein.similarity(each.lower(),wrd.lower()))\n","  return max(score)\n","\n","def sense2vec_get_words(word,s2v,topn,question):\n","    output = []\n","    print (\"word \",word)\n","    try:\n","      sense = s2v.get_best_sense(word, senses= [\"NOUN\", \"PERSON\",\"PRODUCT\",\"LOC\",\"ORG\",\"EVENT\",\"NORP\",\"WORK OF ART\",\"FAC\",\"GPE\",\"NUM\",\"FACILITY\"])\n","      most_similar = s2v.most_similar(sense, n=topn)\n","      # print (most_similar)\n","      output = filter_same_sense_words(sense,most_similar)\n","      print (\"Similar \",output)\n","    except:\n","      output =[]\n","\n","    threshold = 0.6\n","    final=[word]\n","    checklist =question.split()\n","    for x in output:\n","      if get_highest_similarity_score(final,x)<threshold and x not in final and x not in checklist:\n","        final.append(x)\n","\n","    return final[1:]\n","\n","def mmr(doc_embedding, word_embeddings, words, top_n, lambda_param):\n","\n","    # Extract similarity within words, and between words and the document\n","    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n","    word_similarity = cosine_similarity(word_embeddings)\n","\n","    # Initialize candidates and already choose best keyword/keyphrase\n","    keywords_idx = [np.argmax(word_doc_similarity)]\n","    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n","\n","    for _ in range(top_n - 1):\n","        # Extract similarities within candidates and\n","        # between candidates and selected keywords/phrases\n","        candidate_similarities = word_doc_similarity[candidates_idx, :]\n","        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n","\n","        # Calculate MMR\n","        mmr = (lambda_param) * candidate_similarities - (1-lambda_param) * target_similarities.reshape(-1, 1)\n","        mmr_idx = candidates_idx[np.argmax(mmr)]\n","\n","        # Update keywords & candidates\n","        keywords_idx.append(mmr_idx)\n","        candidates_idx.remove(mmr_idx)\n","\n","    return [words[idx] for idx in keywords_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683300977425,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"3eigljekAu9i","outputId":"043da01b-2b48-4437-8034-41cc9d49e3df"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["from collections import OrderedDict\n","from sklearn.metrics.pairwise import cosine_similarity\n","import nltk\n","nltk.download('omw-1.4')\n","\n","def get_distractors_wordnet(word):\n","    distractors=[]\n","    try:\n","      syn = wn.synsets(word,'n')[0]\n","\n","      word= word.lower()\n","      orig_word = word\n","      if len(word.split())>0:\n","          word = word.replace(\" \",\"_\")\n","      hypernym = syn.hypernyms()\n","      if len(hypernym) == 0:\n","          return distractors\n","      for item in hypernym[0].hyponyms():\n","          name = item.lemmas()[0].name()\n","          #print (\"name \",name, \" word\",orig_word)\n","          if name == orig_word:\n","              continue\n","          name = name.replace(\"_\",\" \")\n","          name = \" \".join(w.capitalize() for w in name.split())\n","          if name is not None and name not in distractors:\n","              distractors.append(name)\n","    except:\n","      print (\"Wordnet distractors not found\")\n","    return distractors\n","\n","def get_distractors (word,origsentence,sense2vecmodel,sentencemodel,top_n,lambdaval):\n","  distractors = sense2vec_get_words(word,sense2vecmodel,top_n,origsentence)\n","  print (\"distractors \",distractors)\n","  if len(distractors) ==0:\n","    return distractors\n","  distractors_new = [word.capitalize()]\n","  distractors_new.extend(distractors)\n","  # print (\"distractors_new .. \",distractors_new)\n","\n","  embedding_sentence = origsentence+ \" \"+word.capitalize()\n","  # embedding_sentence = word\n","  keyword_embedding = sentencemodel.encode([embedding_sentence])\n","  distractor_embeddings = sentencemodel.encode(distractors_new)\n","\n","  # filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors,4,0.7)\n","  max_keywords = min(len(distractors_new),5)\n","  filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors_new,max_keywords,lambdaval)\n","  # filtered_keywords = filtered_keywords[1:]\n","  final = [word.capitalize()]\n","  for wrd in filtered_keywords:\n","    if wrd.lower() !=word.lower():\n","      final.append(wrd.capitalize())\n","  final = final[1:]\n","  return final"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":983},"executionInfo":{"elapsed":8097,"status":"ok","timestamp":1683301022121,"user":{"displayName":"gv v","userId":"15728903179935437343"},"user_tz":-330},"id":"Aql5hLirbuSR","outputId":"b3ae16b1-f306-423e-fc27-a0c871862543"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:346: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  warnings.warn(\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n","  warnings.warn(value)\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `keep_filename` parameter is deprecated, and it has no effect\n","  warnings.warn(value)\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:21: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  warnings.warn(\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n","  warnings.warn(value)\n","\n"]},{"name":"stdout","output_type":"stream","text":["IMPORTANT: You are using gradio version 3.9, however version 3.14.0 is available, please upgrade.\n","--------\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","\n","Using Embedded Colab Mode (NEW). If you have issues, please use share=True and file an issue at https://github.com/gradio-app/gradio/\n","Note: opening the browser inspector may crash Embedded Colab Mode.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(<gradio.routes.App at 0x7ff72a310be0>, 'http://127.0.0.1:7860/', None)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import gradio as gr\n","import speech_recognition as sr\n","from moviepy.video.io.VideoFileClip import VideoFileClip\n","\n","def generate_transcript(mp4_file):\n","    video_clip = VideoFileClip(mp4_file.name)\n","    audio_clip = video_clip.audio\n","    audio_file = 'audio.wav'\n","    audio_clip.write_audiofile(audio_file)\n","    r = sr.Recognizer()\n","    with sr.AudioFile(audio_file) as source:\n","        audio_text = r.record(source)\n","    transcript = r.recognize_google(audio_text)\n","    with open('transcript.txt', \"w\") as f:\n","      f.write(transcript)\n","    return transcript\n","\n","mp4_input = gr.inputs.File(label=\"Upload mp4 video\")\n","output_text = gr.outputs.Textbox(label=\"Transcript\")\n","\n","iface = gr.Interface(\n","    fn=generate_transcript,\n","    inputs=mp4_input,\n","    outputs=output_text,\n","    title=\"MP4 to Transcript\",\n","    description=\"Upload an MP4 file to generate a transcript.\",\n",")\n","\n","iface.launch()\n"]},{"cell_type":"markdown","metadata":{"id":"ogiuJdRgg7V6"},"source":["# **Gradio Visualization with MCQs**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AC0i2ECThAqW","executionInfo":{"status":"ok","timestamp":1683303573313,"user_tz":-330,"elapsed":150860,"user":{"displayName":"gv v","userId":"15728903179935437343"}},"outputId":"fce9d623-f15c-43cc-982f-bfaf74a1c951"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:182: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n","  warnings.warn(\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n","  warnings.warn(value)\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["IMPORTANT: You are using gradio version 3.9, however version 3.14.0 is available, please upgrade.\n","--------\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","\n","Using Embedded Colab Mode (NEW). If you have issues, please use share=True and file an issue at https://github.com/gradio-app/gradio/\n","Note: opening the browser inspector may crash Embedded Colab Mode.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7861, \"/\", \"100%\", 500, false, window.element)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["The story is clever fish one day official man was fishing to a river. He threw his net into the river and sat there for switch to get him so that the\n","market could get some good money out of it and sell it in the uk and the rest of the world'sneaky fish' cartoons are now available on hulu.com and you\n","can also subscribe to sonic active skirts channel and press the bell icon to watch new cartoon videos.\n","keywords unsummarized:  ['river', 'day', 'fish', 'man', 'story', 'cartoon videos', 'net', 'bell icon', 'skirts channel', 'switch', 'market', 'money']\n","keywords_found in summarized:  ['bell icon', 'money', 'man', 'skirts channel', 'net', 'cartoon videos', 'market', 'fish', 'river', 'story', 'switch', 'day']\n","\n","\n","Noun phrases ['river', 'day', 'fish', 'man']\n","word  River\n","NOUN\n","Similar  ['Lake', 'Creek', 'Shoreline', 'Small River', 'Shore', 'Large Lake', 'River Bank', 'Big River', 'Riverbed', 'Riverbank', 'Marsh', 'Pond', 'Lagoon', 'Big Lake', 'Canyon', 'River Bed', 'Ravine', 'Sandbar', 'Large River', 'Small Creek', 'Creek Bed', 'Nearby River', 'Small Lake', 'Rivers', 'Mountain', 'Huge Lake', 'Pier', 'Wide River', 'Dunes', 'Little Lake', 'Shore Line', 'Bayou', 'New River', 'Mountain Side', 'Main River', 'Waterway', 'Ocean', 'Sand Dunes']\n","distractors  ['Lake', 'Creek', 'Shoreline', 'Small River', 'Shore', 'Large Lake', 'River Bank', 'Big River', 'Marsh', 'Pond', 'Lagoon', 'Canyon', 'Ravine', 'Sandbar', 'Creek Bed', 'Nearby River', 'Mountain', 'Dunes', 'Bayou', 'Waterway', 'Ocean', 'Sand Dunes']\n","word  Day\n","NOUN\n","Similar  ['Day-', 'Everyday', 'Week', 'Day*.', 'Week-', 'Most Days', 'Whole Day', 'Whole Week', 'Morning', 'Days', 'Other Days', 'Entire Week', 'Night', 'Regular Day', 'Entire Day', 'Time', 'Damn Day', 'Work Days']\n","distractors  ['Everyday', 'Week', 'Most Days', 'Whole Day', 'Morning', 'Other Days', 'Entire Week', 'Night', 'Regular Day', 'Time', 'Damn Day']\n","word  Fish\n","NOUN\n","Similar  ['Shrimp', 'Shrimps', 'Crayfish', 'Most Fish', 'Other Fish', 'Catfish', 'Only Fish', 'Fish Food', 'Snails', 'Trout', 'Crabs', 'Just Fish', 'Large Fish', 'Carp', 'Poultry', 'Salmon', 'Live Fish', 'Freshwater Fish', 'Oysters', 'Quail', 'Fishes', 'Tilapia', 'More Fish', 'Actual Fish', 'Lionfish', 'Seaweed', 'Krill', 'Eel', 'Lobster', 'Mealworms', 'Crab', 'Smaller Fish', 'Halibut', 'Whole Fish', 'Lobsters', 'Mussels', 'Many Fish', 'Few Fish', 'Meat']\n","distractors  ['Shrimp', 'Crayfish', 'Most Fish', 'Other Fish', 'Fish Food', 'Snails', 'Trout', 'Crabs', 'Large Fish', 'Carp', 'Poultry', 'Salmon', 'Freshwater Fish', 'Oysters', 'Quail', 'Tilapia', 'Actual Fish', 'Lionfish', 'Seaweed', 'Krill', 'Eel', 'Lobster', 'Mealworms', 'Smaller Fish', 'Halibut', 'Mussels', 'Meat']\n","word  Man\n","NOUN\n","Similar  ['Man', 'Dude', 'Man-', '&Gt;Man', 'Mister', 'Lad', 'Man', 'Real Man', 'Man/Woman', 'Boy', 'Mate', 'Fella', 'Woman', 'Babe', 'Lass', 'Good Man', 'True Man', 'Guy', 'Homeboy', 'Men', 'Man Man', 'Wo)Man', 'Man*.', 'Lady']\n","distractors  ['Dude', '&Gt;Man', 'Mister', 'Lad', 'Real Man', 'Man/Woman', 'Boy', 'Mate', 'Fella', 'Babe', 'Lass', 'Good Man', 'True Man', 'Guy', 'Homeboy', 'Wo)Man']\n","Keyboard interruption in main thread... closing server.\n"]},{"output_type":"execute_result","data":{"text/plain":["(<gradio.routes.App at 0x7ff72a05d9f0>, 'http://127.0.0.1:7861/', None)"]},"metadata":{},"execution_count":16}],"source":["import gradio as gr\n","\n","output = gr.outputs.HTML(  label=\"Question and Answers\")\n","radiobutton = gr.inputs.Radio([\"Wordnet\", \"Sense2Vec\"])\n","\n","def generate_question(radiobutton):\n","  with open('/content/transcript.txt', 'r') as file:\n","      context = file.read()\n","  summary_text = summarizer(context, summary_model, summary_tokenizer)\n","  for wrp in wrap(summary_text, 150):\n","    print (wrp)\n","  # np = getnounphrases(summary_text,sentence_transformer_model,3)\n","  np =  get_keywords(context, summary_text)\n","  print (\"\\n\\nNoun phrases\",np)\n","  output=\"\"\n","  for answer in np:\n","    ques = get_question(summary_text,answer,question_model,question_tokenizer)\n","    if radiobutton==\"Wordnet\":\n","      distractors = get_distractors_wordnet(answer)\n","    else:\n","      distractors = get_distractors(answer.capitalize(),ques,s2v,sentence_transformer_model,40,0.2)\n","    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n","    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n","    output = output + \"<br>\"\n","    output = output + \"<b style='color:green;'>\" +answer.capitalize()+  \"</b>\"+\"<br>\"\n","    if len(distractors)>0:\n","      for distractor in distractors[:4]:\n","        output = output + \"<b style='color:brown;'>\" + distractor+  \"</b>\"+\"<br>\"\n","    output = output + \"<br>\"\n","\n","  summary =\"Summary: \"+ summary_text\n","  for answer in np:\n","    summary = summary.replace(answer,\"<b>\"+answer+\"</b>\" + \"<br>\")\n","    summary = summary.replace(answer.capitalize(),\"<b>\"+answer.capitalize()+\"</b>\")\n","  output = output + \"<p>\"+summary+\"</p>\"\n","  output = output + \"<br>\"\n","  return output\n","\n","\n","iface = gr.Interface(\n","  fn=generate_question,\n","  inputs=radiobutton,\n","  outputs=output)\n","iface.launch(debug=True)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1_Kqm0zShBLlN0-9Q-W25jQSQFPcmPhyu","timestamp":1687451912200},{"file_id":"1S2VDmx67ST94KIuyIjzUoDRCEHb9qx7T","timestamp":1683303651641},{"file_id":"1FQTslbG7i59RehJbYLTNuucWT4MwWxOF","timestamp":1683296016319},{"file_id":"1OzUPifaACHRZabqYOIMTEfniDdTC_M0h","timestamp":1682772938388},{"file_id":"1-akhQXoTJaaJ6Gm3XofNwAUcbvSezCUa","timestamp":1678206895827},{"file_id":"1dSh4aUYyG5mSAA3LHO2TJUsJnIQyajLd","timestamp":1678206858817}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}